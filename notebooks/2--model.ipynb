{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c89ed039",
   "metadata": {},
   "source": [
    "# Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cd6db7",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff5c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from ipynb_utils import CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de586a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = CFG[\"DATA_DIR\"]\n",
    "\n",
    "# Paths from which the data frame will be loaded.\n",
    "DF_PKL_PATH_SRC = os.path.join(DATA_DIR, \"df_processed.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13452c2",
   "metadata": {},
   "source": [
    "As main evaluation metric, we decide for recall: The number of detected diabetes diseases should be as large as possible. We want to consider it more serious to label people with disease as healthy than declaring people without disease as ill. Of course, this is not apodictory. Have to compare the consequences of superfluous treatment with omitted treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6860486",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(DF_PKL_PATH_SRC)\n",
    "\n",
    "# # TODO: Remove all missing values\n",
    "# df = df.fillna(0)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70b931a",
   "metadata": {},
   "source": [
    "Split data by pseudo-feature we introduces already in the [previous notebook](./1--analysis.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d289e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df[\"is_test\"] == 0]\n",
    "df_1 = df[df[\"is_test\"] != 0]\n",
    "\n",
    "X_cols_blacklist = [\n",
    "    \"id\",\n",
    "    \"has_diabetes\",\n",
    "    \"is_test\",\n",
    "]\n",
    "\n",
    "X_cols = [col for col in df.columns if col not in X_cols_blacklist]\n",
    "y_col = \"has_diabetes\"\n",
    "\n",
    "X_0 = df_0[X_cols]\n",
    "X_1 = df_1[X_cols]\n",
    "y_0 = df_0[y_col]\n",
    "y_1 = df_1[y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcc4e91",
   "metadata": {},
   "source": [
    "## Simple Logistic Regression Model\n",
    "\n",
    "As baseline model for benchmarking, we employ a logistic regression that takes only the age and the bmi of participant into account.\n",
    "\n",
    "Furthermore, we oversample and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2229e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols_red = [\"age\", \"bmi\"]\n",
    "\n",
    "# ColumnTransformer to select columns\n",
    "feature_selector = ColumnTransformer([(\"selector\", \"passthrough\", X_cols_red)])\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        # Feature selection\n",
    "        (\"feature_selector\", feature_selector),\n",
    "        # Oversampler\n",
    "        (\"oversampler\", RandomOverSampler(random_state=CFG[\"RSEED\"])),\n",
    "        # Scaler for features (target scaling is not necessary)\n",
    "        (\"scaler\", MinMaxScaler()),\n",
    "        # Logistic regression\n",
    "        (\"model\", LogisticRegression(random_state=CFG[\"RSEED\"])),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bb0228",
   "metadata": {},
   "source": [
    "Fit model, cross calidation. As the parameters of a logistic regression have also a visually pleasing explanation, let us also calculate these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc215496",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid={},\n",
    "    cv=10,\n",
    "    scoring=\"accuracy\",\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_0, y_0)\n",
    "\n",
    "estimator = grid_search.best_estimator_\n",
    "\n",
    "steps = estimator.named_steps\n",
    "\n",
    "model = steps[\"model\"]\n",
    "coef_scaled = model.coef_[0]\n",
    "intercept_scaled = model.intercept_[0]\n",
    "\n",
    "scaler = steps[\"scaler\"]\n",
    "data_min = scaler.data_min_ \n",
    "data_max = scaler.data_max_ \n",
    "data_range = data_max - data_min \n",
    "\n",
    "# Back-transform coefficients to original scale\n",
    "coef_orig = coef_scaled / data_range\n",
    "\n",
    "# Adjust intercept for original scale\n",
    "intercept_orig = intercept_scaled - np.sum(coef_scaled * data_min / data_range)\n",
    "\n",
    "print(\"Best parameters :\")\n",
    "print(f\"  Coefficients : {coef_orig}\")\n",
    "print(f\"  Intercept    : {intercept_orig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3996741",
   "metadata": {},
   "source": [
    "The coefficients are positive, as expected: The older or the more likely a diabetes disease occur, and analogously for the BMI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dd2c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict or evaluate on test data (full X_1 dataframe, pipeline selects columns internally)\n",
    "z_1 = estimator.predict(X_1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_1, z_1))\n",
    "\n",
    "tpr = recall_score(y_1, z_1, pos_label=1)\n",
    "print(f\"True Positive Rate (Recall): {tpr:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354de681",
   "metadata": {},
   "source": [
    "First, some preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54045817",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_palette = {\n",
    "    \"TP\": \"green\",\n",
    "    \"TN\": \"blue\",\n",
    "    \"FP\": \"red\",\n",
    "    \"FN\": \"orange\",\n",
    "}\n",
    "\n",
    "\n",
    "def classify_outcome(row):\n",
    "    if row[\"diagnosis\"] == 1:\n",
    "        if row[\"prognosis\"] == 1:\n",
    "            return \"TP\" \n",
    "        else:\n",
    "            return \"FN\"\n",
    "    else:\n",
    "        if row[\"prognosis\"] == 1:\n",
    "            return \"FP\"\n",
    "        else:\n",
    "            return \"TN\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1c3d3e",
   "metadata": {},
   "source": [
    "For error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_1, z_1)\n",
    "sns.heatmap(cm, cmap=\"YlGnBu_r\", annot=True, fmt=\".0f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ac87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot part\n",
    "\n",
    "# Frame holding the data for plotting.\n",
    "df_plot = X_1[[\"age\", \"bmi\"]].copy()\n",
    "df_plot[\"diagnosis\"] = y_1\n",
    "df_plot[\"prognosis\"] = z_1\n",
    "df_plot[\"outcome\"] = df_plot.apply(classify_outcome, axis=1)\n",
    "\n",
    "# Scatterplot\n",
    "sns.scatterplot(\n",
    "    data=df_plot,\n",
    "    x=\"age\",\n",
    "    y=\"bmi\",\n",
    "    hue=\"outcome\",\n",
    "    palette=outcome_palette,\n",
    "    s=20,\n",
    "    edgecolor=\"k\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "# Decision boundary part\n",
    "\n",
    "# The decision boundary is described by \n",
    "# age_coeff * age + bmi_coeff * bmi + intercept = 0.\n",
    "# We resolve this equation for bmi.\n",
    "\n",
    "# Range of age\n",
    "xx = np.array([df_plot[\"age\"].min() - 1, df_plot[\"age\"].max() + 1])\n",
    "\n",
    "# Corresponding bmi values on the decision boundary line\n",
    "yy = -(intercept_orig + coef_orig[0] * xx) / coef_orig[1]\n",
    "\n",
    "# Plot decision boundary line\n",
    "plt.plot(xx, yy, \"k--\", linewidth=2, label=\"Decision Boundary\")\n",
    "\n",
    "# Finalisation of the plot\n",
    "\n",
    "plt.xlabel(\"Age (years)\")\n",
    "plt.ylabel(\"BMI (kg/sqm)\")\n",
    "plt.title(\"Classification Results with Decision Boundary\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413ed7de",
   "metadata": {},
   "source": [
    "## Decision Tree Model\n",
    "\n",
    "As Machine Learning model which aims to optimise our target evaluation metric, we choose a decision tree classificator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c18f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols_blacklist = [\"dpf\", \"date\"]\n",
    "X_cols_red = [col for col in X_cols if col not in X_cols_blacklist]\n",
    "\n",
    "feature_selector = ColumnTransformer([(\"selector\", \"passthrough\", X_cols_red)])\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        # Feature selection\n",
    "        (\"feature_selector\", feature_selector),\n",
    "        # Oversampler\n",
    "        (\"oversampler\", RandomOverSampler(random_state=CFG[\"RSEED\"])),\n",
    "        # Scaling is not strictly necessary for Decision Trees\n",
    "        # (\"scaler\", MinMaxScaler()),\n",
    "        # Decision tree classifier\n",
    "        (\"model\", DecisionTreeClassifier(random_state=CFG[\"RSEED\"])),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880bf445",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"model__max_depth\": [2, 4, 8, 16, None],\n",
    "    \"model__min_samples_split\": [2, 4, 8],\n",
    "    \"model__min_samples_leaf\": [1, 2, 4, 8],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"recall\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_0, y_0)\n",
    "\n",
    "print(\"Best parameters :\")\n",
    "pad = max([len(k) for k in param_grid]) + 1\n",
    "for k,v in grid_search.best_params_.items():\n",
    "    print(f\"  {k:{pad}}: {v}\")\n",
    "print(\"Best CV score   :\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9aa1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_1 = grid_search.predict(X_1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_1, z_1))\n",
    "\n",
    "tpr = recall_score(y_1, z_1, pos_label=1)\n",
    "print(f\"True Positive Rate (Recall): {tpr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8424134",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_1, z_1)\n",
    "sns.heatmap(cm, cmap=\"YlGnBu_r\", annot=True, fmt=\".0f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee86818",
   "metadata": {},
   "source": [
    "There is no clear decision boundary anymore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame holding the data for plotting.\n",
    "df_plot = X_1[[\"age\", \"bmi\"]].copy()\n",
    "df_plot[\"diagnosis\"] = y_1\n",
    "df_plot[\"prognosis\"] = z_1\n",
    "df_plot[\"outcome\"] = df_plot.apply(classify_outcome, axis=1)\n",
    "\n",
    "# Scatterplot\n",
    "sns.scatterplot(\n",
    "    data=df_plot,\n",
    "    x=\"age\",\n",
    "    y=\"bmi\",\n",
    "    hue=\"outcome\",\n",
    "    palette=outcome_palette,\n",
    "    s=20,\n",
    "    edgecolor=\"k\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "# Finalisation of the plot\n",
    "\n",
    "plt.xlabel(\"Age (years)\")\n",
    "plt.ylabel(\"BMI (kg/sqm)\")\n",
    "plt.title(\"Classification Results with Decision Boundary\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
