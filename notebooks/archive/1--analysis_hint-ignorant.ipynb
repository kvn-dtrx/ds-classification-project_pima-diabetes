{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77c15aa7",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "This notebook presents an analysis of the data under the hypothetical assumption that we had not been informed of the presence of a (moderately noisy) duplication within the original data frame.\n",
    "\n",
    "The following modules shall be employed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dac7a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "\n",
    "from ipynb_utils import CFG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c317d7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c62e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = CFG[\"DATA_DIR\"]\n",
    "\n",
    "# Path from which data frames will be loaded\n",
    "DF_PKL_PATH_SRC = os.path.join(DATA_DIR, \"df_raw.pkl\") \n",
    "DF_PKL_PATH_TAR = os.path.join(DATA_DIR, \"df_processed.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5baa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(DF_PKL_PATH_SRC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1929d80c",
   "metadata": {},
   "source": [
    "## Date of Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64030ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda2f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5750985",
   "metadata": {},
   "source": [
    "We see we have only 768 different ids but 1536 (2 * 768) columns. The paper also only mentions 768 examinations. But we have two dates of measurement. Therefore, tt could be possible that each patient was examined at two different times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71511430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series with number of dates per id.\n",
    "s = df.groupby(\"id\")[\"date\"].nunique()\n",
    "\n",
    "# Unique values in this series.\n",
    "s.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eec1b9a",
   "metadata": {},
   "source": [
    "We can conclude that for each patient, are exactly two measurement recorded, one on 2022-12-01 and the other on 2022-12-13.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b5d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = df.sort_values([\"id\", \"date\"])  # ensure correct order\n",
    "df_wide[\"rank\"] = df_wide.groupby(\"id\").cumcount()\n",
    "\n",
    "df_wide = df_wide.pivot(index=\"id\", columns=\"rank\")\n",
    "df_wide.columns = [f\"{col}_{order}\" for col, order in df_wide.columns]\n",
    "df_wide = df_wide.reset_index()\n",
    "\n",
    "df_wide.nunique()\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a2869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if col not in [\"id\", \"date\"]]\n",
    "\n",
    "\n",
    "cols_0 = [f\"{s}_0\" for s in cols]\n",
    "cols_1 = [f\"{s}_1\" for s in cols]\n",
    "cols_delta = [f\"{s}_delta\" for s in cols]\n",
    "\n",
    "df_wide[cols_delta] = df_wide[cols_1].values - df_wide[cols_0].values\n",
    "\n",
    "# # Construct new DataFrame with diff_ column names\n",
    "# df_diff = pd.DataFrame(df_diff, columns=[f\"{s}_delta\" for s in cols])\n",
    "# df_diff.insert(0, \"id\", df_wide[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c275b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delta = df_wide[cols_delta]\n",
    "\n",
    "# df_delta.sample(10)\n",
    "\n",
    "df_wide.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = []\n",
    "\n",
    "# Date columns\n",
    "cols_to_drop.extend([col for col in df_wide.columns if col.startswith(\"date_\")])\n",
    "\n",
    "#\n",
    "cols_to_drop.extend([col for col in df_wide.columns if col in cols_1])\n",
    "\n",
    "# Identically vanishing delta columns.\n",
    "df_tmp = df_delta.nunique()\n",
    "cols_delta_rm = df_tmp[df_tmp == 1].index.tolist()\n",
    "cols_to_drop.extend([col for col in df_wide.columns if col in cols_delta_rm])\n",
    "\n",
    "df_wide = df_wide.drop(columns=cols_to_drop)\n",
    "\n",
    "df_wide = df_wide.rename(\n",
    "    columns={\n",
    "        col: col.replace(\"_0\", \"\") for col in df_wide.columns if col.endswith(\"_0\")\n",
    "    }\n",
    ")\n",
    "\n",
    "# Sort columns as follows:\n",
    "# id, features lexicographically, target.\n",
    "features_sorted = sorted(\n",
    "    [col for col in df_wide.columns if col not in [\"id\", \"has_diabetes\"]]\n",
    ")\n",
    "cols = [\"id\"] + features_sorted + [\"has_diabetes\"]\n",
    "df_wide = df_wide[cols]\n",
    "\n",
    "df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7b6d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df_wide.columns if col not in [\"id\", \"has_diabetes\"]]\n",
    "\n",
    "fig, axes = plt.subplots(5, 2, figsize=(12, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    ax = axes[i]\n",
    "    sns.histplot(data=df_wide, x=col, ax=ax, color=\"black\", linestyle=\"--\")\n",
    "    ax.set_title(col)\n",
    "    # ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ca2f5",
   "metadata": {},
   "source": [
    "Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5098757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_wide.drop(columns=[\"id\"])\n",
    "corr = df_.corr()\n",
    "\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", square=True)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02a465",
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = [\"bloodpressure_delta\", \"glucose_delta\"]\n",
    "\n",
    "cols_to_drop = [\n",
    "    col for col in df_wide.columns if col in [\"\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb95247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to root directory of the repo.\n",
    "root_dir_ = subprocess.check_output(\n",
    "    [\"git\", \"rev-parse\", \"--show-toplevel\"],\n",
    "    text=True,\n",
    ")\n",
    "ROOT_DIR = root_dir_.strip()\n",
    "# Path to data directory.\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "# Path from which dataframe will be loaded\n",
    "DF_PKL_PATH_SRC = os.path.join(DATA_DIR, \"df_raw.pkl\") \n",
    "DF_PKL_PATH_TAR = os.path.join(DATA_DIR, \"df_processed.pkl\")\n",
    "\n",
    "\n",
    "plt.style.use('tableau-colorblind10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec56f064",
   "metadata": {},
   "source": [
    "After that, we could resume the treatment of missing values in the same way as we perform it in the [main analysis notebook](../2--analysis.ipynb) where we turn unrealistic zero values to NULL values. We merely have to to take care that we also mark affected cells in the columns matching \"*_delta\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
