{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77c15aa7",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "This notebook presents an analysis of the data under the hypothetical assumption that we had not been informed of the presence of a (moderately noisy) duplication within the original data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b8da1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The following modules shall be employed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dac7a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipynb_utils import CFG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c317d7",
   "metadata": {},
   "source": [
    "We specify the location at which the data are stored on disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c62e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = CFG[\"DATA_DIR\"]\n",
    "\n",
    "DF_PKL_PATH_SRC = os.path.join(DATA_DIR, \"df_duplicate.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2938e2",
   "metadata": {},
   "source": [
    "Then, the content of the file is loaded into a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5baa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(DF_PKL_PATH_SRC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1929d80c",
   "metadata": {},
   "source": [
    "## Unstacking Paired Measurement Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2686becb",
   "metadata": {},
   "source": [
    "Let us take a glance at the number of unique values within the individual features, as well as at the values of the feature `\"date\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64030ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda2f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5750985",
   "metadata": {},
   "source": [
    "We observe that there are only $768$ distinct IDs but $1536$ ($= 2 \\times 768$) rows. Likewise, the attached paper mentions 768 examinations. However, there are two dates of measurement suggesting that each patient was examined on two separate occasions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71511430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series with number of dates per \"id\".\n",
    "s = df.groupby(\"id\")[\"date\"].nunique()\n",
    "\n",
    "# Unique values in this series.\n",
    "s.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eec1b9a",
   "metadata": {},
   "source": [
    "We may conclude that for each patient there are exactly two measurements recorded, one on 2022-12-01 and the other on 2022-12-13.\n",
    "\n",
    "Following this observation, we create a data frame containing the two measurements for each patient. Columns suffixed with `\"_0\"` or `\"_1\"` indicate the first or second measurement in chronological order, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b5d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort columns first by \"id\", then by \"date\".\n",
    "df_wide = df.sort_values([\"id\", \"date\"])\n",
    "\n",
    "# Index the measurement per \"id\".\n",
    "df_wide[\"rank\"] = df_wide.groupby(\"id\").cumcount()\n",
    "\n",
    "# Reshape data frame. Rows are indexed by values in\n",
    "# the \"id\" column, columns are created for each unique\n",
    "# value in the \"rank\" column.\n",
    "df_wide = df_wide.pivot(index=\"id\", columns=\"rank\")\n",
    "\n",
    "# Flatten column names from tuples to plain strings.\n",
    "df_wide.columns = [f\"{col}_{order}\" for col, order in df_wide.columns]\n",
    "\n",
    "# Convert \"id\" to a regular column.\n",
    "df_wide = df_wide.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac68ff07",
   "metadata": {},
   "source": [
    "From these pairs of measurements, we construct the corresponding difference columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a2869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns for which a difference column shall be created. \n",
    "cols = [col for col in df.columns if col not in [\"id\", \"date\"]]\n",
    "\n",
    "# Columns associated with the first measurment.\n",
    "cols_0 = [f\"{s}_0\" for s in cols]\n",
    "# Columns associated with the second measurment.\n",
    "cols_1 = [f\"{s}_1\" for s in cols]\n",
    "# Columns associated with the difference of both measurments.\n",
    "cols_delta = [f\"{s}_delta\" for s in cols]\n",
    "\n",
    "df_wide[cols_delta] = df_wide[cols_1].values - df_wide[cols_0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969bd358",
   "metadata": {},
   "source": [
    "However, the new data frame still contains redundant information. On the one hand, the date-related columns have become obsolete. On the other hand, the values for the second measurement are entirely determined by those of the first measurement and the difference; consequently, they ought to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c3ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "\n",
    "# Date columns.\n",
    "cols.extend([col for col in df_wide.columns if col.startswith(\"date_\")])\n",
    "\n",
    "# Columns associated with second measurement.\n",
    "cols.extend([col for col in df_wide.columns if col in cols_1])\n",
    "\n",
    "df_wide = df_wide.drop(columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc69e7ef",
   "metadata": {},
   "source": [
    "Consequently, a suffix for columns related to the first measurement is no longer necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852c4c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = df_wide.rename(\n",
    "    columns={\n",
    "        col: col.replace(\"_0\", \"\") for col in df_wide.columns if col.endswith(\"_0\")\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdec0ea",
   "metadata": {},
   "source": [
    "## Difference Columns\n",
    "\n",
    "Let us examine the difference columns in greater detail. A glance at the number of unique values reveals which of these features are not trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c275b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide[cols_delta].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d48263",
   "metadata": {},
   "source": [
    "Naturally, constant columns do not contribute to explanatory power; therefore, it is safe to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta columns containing at most one distinct non-NULL value.\n",
    "df_tmp = df_wide[cols_delta].nunique()\n",
    "cols = df_tmp[df_tmp <= 1].index.tolist()\n",
    "\n",
    "df_wide = df_wide.drop(columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8970d3a2",
   "metadata": {},
   "source": [
    "Let us proceed with the renaming and reordering of columns for the sake of convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b84db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort columns as follows:\n",
    "# id, features lexicographically, target.\n",
    "features_sorted = sorted(\n",
    "    [col for col in df_wide.columns if col not in [\"id\", \"has_diabetes\"]]\n",
    ")\n",
    "\n",
    "cols = [\"id\"] + features_sorted + [\"has_diabetes\"]\n",
    "df_wide = df_wide[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986f49ee",
   "metadata": {},
   "source": [
    "The following plots may provide a visual impression of the individual feature distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7b6d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df_wide.columns if col not in [\"id\", \"has_diabetes\"]]\n",
    "\n",
    "fig, axes = plt.subplots(6, 2, figsize=(12, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    ax = axes[i]\n",
    "    sns.histplot(data=df_wide, x=col, ax=ax, color=\"black\", linestyle=\"--\", bins=25)\n",
    "    ax.set_title(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ca2f5",
   "metadata": {},
   "source": [
    "Furthermore, we shall examine the correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5098757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_wide.drop(columns=[\"id\"])\n",
    "corr = df_tmp.corr()\n",
    "\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", square=True)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd4566",
   "metadata": {},
   "source": [
    "The correlation between `\"glucose\"` and `\"glucose_delta\"` is highly significant; therefore, the removal of the difference column may be justified. *Mutatis mutandis*, the same applies to the columns related to blood pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02a465",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_blacklist = [\n",
    "    \"bloodpressure_delta\", \n",
    "    \"glucose_delta\",\n",
    "]\n",
    "\n",
    "cols = [\n",
    "    col for col in df_wide.columns if col not in cols_blacklist\n",
    "]\n",
    "\n",
    "df_wide = df_wide.drop(columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763e2b00",
   "metadata": {},
   "source": [
    "However, the correlation between `\"insulin\"` and `\"insulin_delta\"` is too weak to warrant the removal of the difference column. A more sophisticated analysis would be required at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec56f064",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "Thereafter, we may resume the treatment of missing values in the same manner as in the [main analysis notebook](../2--analysis.ipynb). When converting implausible zero values to `NULL` values, care must also be taken to mark the corresponding cells in the columns matching `\"*_delta\"`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
