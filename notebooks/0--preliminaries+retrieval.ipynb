{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7fe3038",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "Here, we explain briefly how we organise our notebooks. Throughout all notebooks, we shall employ a custom module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b5f31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a94275c",
   "metadata": {},
   "source": [
    "It contains a configuration dictionary named `CFG` which holds global environment variables. This shall facilitate the process of storing and loading data between notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc373c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = ipynb_utils.CFG\n",
    "\n",
    "padding_length = max([len(k) for k in CFG])\n",
    "\n",
    "print(\"CFG Dictionary:\")\n",
    "for k, v in CFG.items():\n",
    "    print(f\"  {k:{padding_length}} : {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7079ddc3",
   "metadata": {},
   "source": [
    "Finally, let us delineate the contents of our notebooks and the data upon which they respectively depend:\n",
    "\n",
    "- `0--preliminaries+retrieval.ipynb`: The present notebook. the code that retrieves the data can be found in the subsequent section.\n",
    "\n",
    "TODO:\n",
    "- `1--retrieval.ipynb`: Describes the procedure to download `train.csv` (`CFG[\"TRAIN_DATA_PATH\"]`) and also downloads `airports.csv` (`CFG[\"AIRPORTS_DATA_PATH\"]`). Both files are requisite for the remaining notebook.\n",
    "- `1-1--eda-basic.ipynb`: Conducts basic exploratory data analysis, producing a processed data frame `df.pkl` (`CFG[\"PROCESSED_DATA_PATH\"]`). This file is necessary for all subsequent notebooks.\n",
    "- `1-*--eda-add_*.ipynb`: Additional exploratory data analysis, each independent of the others.\n",
    "- `2-*--model_*.ipynb`: Machine Learning models, each independent of the others.\n",
    "\n",
    "In the `archive/` directory, the reader may find two additional notebooks:\n",
    "\n",
    "TODO:\n",
    "- `0--retrieval_kaggle.ipynb`: Describes the procedure to download the data via kaggleâ€”with appropriate credentials.\n",
    "- `1--analysis_hint-ignorant.ipynb`: Provides a data analysis under where we pretend to ignore the fact that the instructors meant to insert a duplication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9a15ee",
   "metadata": {},
   "source": [
    "# Data Retrieval\n",
    "\n",
    "In this notebook, we shall provide the code required to retrieve the data intended for analysis. It should be noted that appropriate credentials must be supplied in order to access the database.\n",
    "\n",
    "We shall employ the following modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58a1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191764c8",
   "metadata": {},
   "source": [
    "Global configs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f64a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = CFG[\"DATA_DIR\"]\n",
    "\n",
    "# HTTP address of the (public) repository.\n",
    "HTTP_REPO_URL = \"https://github.com/davidmegginson/ourairports-data\"\n",
    "\n",
    "# Path of the csv file relative to the (remote) repository root.\n",
    "CSV_PATH_REL = \"airports.csv\"\n",
    "\n",
    "# Target path of the csv file on the local machine.\n",
    "AIRPORTS_DATA_PATH = CFG[\"AIRPORTS_DATA_PATH\"]\n",
    "\n",
    "# Full HTTP address of the csv file.\n",
    "http_url = f\"{HTTP_REPO_URL}/blob/main/{CSV_PATH_REL}\"\n",
    "\n",
    "# Paths to which dataframes will be saved\n",
    "DF_PKL_PATH_TAR = os.path.join(DATA_DIR, \"df_raw.pkl\")\n",
    "DF_CSV_PATH_TAR = os.path.join(DATA_DIR, \"df_raw.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7faf220",
   "metadata": {},
   "source": [
    "A brief examination of the given database, conducted within a GUI application such as DBeaver, reveals that the following SQL query yields the correct dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01cbbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\"\n",
    "    SET SCHEMA 'diabetes';\n",
    "\n",
    "    SELECT * FROM\n",
    "            patient p\n",
    "        LEFT JOIN\n",
    "            blood_metrics bm\n",
    "        ON p.id = bm.patientid\n",
    "        LEFT JOIN\n",
    "            pedigree_outcome po\n",
    "        ON p.id = po.patientid\n",
    "        LEFT JOIN\n",
    "            skin s\n",
    "        ON p.id = s.patientid\n",
    "    ;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb44397",
   "metadata": {},
   "source": [
    "We load the credentials required for database access from the `.env` file into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4d8347",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"name\": os.getenv(\"DB_NAME\"),\n",
    "    \"scheme\": os.getenv(\"DB_SCHEME\"),\n",
    "    \"user\": os.getenv(\"DB_USER\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_PORT\")\n",
    "}\n",
    "\n",
    "DB_URI = (\n",
    "    \"{scheme}://{user}:{password}@{host}:{port}/{name}\"\n",
    "    .format(**DB_CONFIG)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b10ec9",
   "metadata": {},
   "source": [
    "We establish a connection with the database and load the data specified by the query into a pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeede5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = create_engine(DB_URI)\n",
    "\n",
    "with db.connect() as conn:\n",
    "    df = pd.read_sql(QUERY, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f678d10",
   "metadata": {},
   "source": [
    "Let us confirm that the download process has been successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc60988",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240154c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c493bd8b",
   "metadata": {},
   "source": [
    "The join operation in the SQL query may cause duplication of columns. Further, the column \"patientid\" is identical to \"id\". We shall remove such duplicates immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba54c0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "if \"patientid\" in df.columns:\n",
    "    df = df.drop(columns=[\"patientid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba19e73",
   "metadata": {},
   "source": [
    "At last, the data frame is ready to be stored: To preserve the original data structure, we employ a pickle file; the csv version serves solely for direct visual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aef3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(DF_PKL_PATH_TAR)\n",
    "df.to_csv(DF_CSV_PATH_TAR, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
